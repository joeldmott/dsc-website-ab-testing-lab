{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website A/B Testing - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll get another chance to practice your skills at conducting a full A/B test analysis. It will also be a chance to practice your data exploration and processing skills! The scenario you'll be investigating is data collected from the homepage of a music app page for audacity.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Analyze the data from a website A/B test to draw relevant conclusions\n",
    "* Explore and analyze web action data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "Start by loading in the dataset stored in the file 'homepage_actions.csv'. Then conduct an exploratory analysis to get familiar with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hints:\n",
    "    * Start investigating the id column:\n",
    "        * How many viewers also clicked?\n",
    "        * Are there any anomalies with the data; did anyone click who didn't view?\n",
    "        * Is there any overlap between the control and experiment groups? \n",
    "            * If so, how do you plan to account for this in your experimental design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-24 17:42:27.839496</td>\n",
       "      <td>804196</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-24 19:19:03.542569</td>\n",
       "      <td>434745</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-24 19:36:00.944135</td>\n",
       "      <td>507599</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-24 19:59:02.646620</td>\n",
       "      <td>671993</td>\n",
       "      <td>control</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-24 20:26:14.466886</td>\n",
       "      <td>536734</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp      id       group action\n",
       "0  2016-09-24 17:42:27.839496  804196  experiment   view\n",
       "1  2016-09-24 19:19:03.542569  434745  experiment   view\n",
       "2  2016-09-24 19:36:00.944135  507599  experiment   view\n",
       "3  2016-09-24 19:59:02.646620  671993     control   view\n",
       "4  2016-09-24 20:26:14.466886  536734  experiment   view"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "df = pd.read_csv('homepage_actions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#flatiron_stats\n",
      "import numpy as np\n",
      "import scipy.stats as stats\n",
      "\n",
      "def welch_t(a, b):\n",
      "    \n",
      "    \"\"\" Calculate Welch's t statistic for two samples. \"\"\"\n",
      "\n",
      "    numerator = a.mean() - b.mean()\n",
      "    \n",
      "    # â€œddof = Delta Degrees of Freedomâ€�: the divisor used in the calculation is N - ddof, \n",
      "    #  where N represents the number of elements. By default ddof is zero.\n",
      "    \n",
      "    denominator = np.sqrt(a.var(ddof=1)/a.size + b.var(ddof=1)/b.size)\n",
      "    \n",
      "    return np.abs(numerator/denominator)\n",
      "\n",
      "def welch_df(a, b):\n",
      "    \n",
      "    \"\"\" Calculate the effective degrees of freedom for two samples. This function returns the degrees of freedom \"\"\"\n",
      "    \n",
      "    s1 = a.var(ddof=1) \n",
      "    s2 = b.var(ddof=1)\n",
      "    n1 = a.size\n",
      "    n2 = b.size\n",
      "    \n",
      "    numerator = (s1/n1 + s2/n2)**2\n",
      "    denominator = (s1/ n1)**2/(n1 - 1) + (s2/ n2)**2/(n2 - 1)\n",
      "    \n",
      "    return numerator/denominator\n",
      "\n",
      "\n",
      "def p_value_welch_ttest(a, b, two_sided=False):\n",
      "    \"\"\"Calculates the p-value for Welch's t-test given two samples.\n",
      "    By default, the returned p-value is for a one-sided t-test. \n",
      "    Set the two-sided parameter to True if you wish to perform a two-sided t-test instead.\n",
      "    \"\"\"\n",
      "    t = welch_t(a, b)\n",
      "    df = welch_df(a, b)\n",
      "    \n",
      "    p = 1-stats.t.cdf(np.abs(t), df)\n",
      "    \n",
      "    if two_sided:\n",
      "        return 2*p\n",
      "    else:\n",
      "        return p\n"
     ]
    }
   ],
   "source": [
    "!cat flatiron_stats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatiron_stats as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8188 entries, 0 to 8187\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   timestamp  8188 non-null   object\n",
      " 1   id         8188 non-null   int64 \n",
      " 2   group      8188 non-null   object\n",
      " 3   action     8188 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 256.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-09-24 17:42:27.839496'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-01-18 10:24:08.629327'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control       4264\n",
       "experiment    3924\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view     6328\n",
       "click    1860\n",
       "Name: action, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['action'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My notes I didn't really understand the questions above \"How many viewers also clicked? * Are there any anomalies with the data; did anyone click who didn't view?\" because it seems like my 'action' value counts kind of answers it already. However, in the spirit of learning more, let's do it this way as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of viewers: 6328, /t Number of clickers: 1860\n"
     ]
    }
   ],
   "source": [
    "#view_ids = df['id']['action' == 'view'].unique()\n",
    "\n",
    "#No, you (1) make it a set and (2) put the condition first, I guess:\n",
    "view_ids = set(df[df.action=='view']['id'].unique())\n",
    "click_ids = set(df[df.action=='click']['id'].unique())\n",
    "print(\"Number of viewers: {}, /t Number of clickers: {}\".format(len(view_ids), len(click_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of viewers who didn't click: 4468\n",
      "Number of clickers who didn't view: -4468\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of viewers who didn't click: {}\".format(len(view_ids) - len(click_ids)))\n",
    "print(\"Number of clickers who didn't view: {}\".format(len(click_ids) - len(view_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing is making sure our control & experiment groups don't overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlap between experiment & control id numbers: 0\n"
     ]
    }
   ],
   "source": [
    "#control_ids = set(df.group == 'control')['id'].unique()\n",
    "control_ids = set(df[df.group == 'control']['id'].unique())\n",
    "experiment_ids = set(df[df.group == 'experiment']['id'].unique())\n",
    "#overlap = experiment_ids.isin(control_ids)\n",
    "print(\"Number of overlap between experiment & control id numbers: {}\".format(len(control_ids&experiment_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct a Statistical Test\n",
    "\n",
    "Conduct a statistical test to determine whether the experimental homepage was more effective than that of the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>control</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>control</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8187</th>\n",
       "      <td>control</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           group action\n",
       "0     experiment   view\n",
       "1     experiment   view\n",
       "2     experiment   view\n",
       "3        control   view\n",
       "4     experiment   view\n",
       "...          ...    ...\n",
       "8183  experiment   view\n",
       "8184  experiment   view\n",
       "8185  experiment   view\n",
       "8186     control   view\n",
       "8187     control   view\n",
       "\n",
       "[8188 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "#We'll set up a contingency table by first filtering the df for the group and action columns\n",
    "# only. Then, we'll set up filter A and filter B for the control & experiment groups. \n",
    "\n",
    "#filtered_df = df[df['group', 'action']]\n",
    "\n",
    "#Nope, don't need the second 'df' in there:\n",
    "filtered_df = df[['group', 'action']]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(932, 928)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_A = filtered_df[filtered_df['group'] == 'control']\n",
    "filtered_df_B = filtered_df[filtered_df['group'] == 'experiment']\n",
    "\n",
    "control_clicks = sum(filtered_df_A['action'] == 'click')\n",
    "experiment_clicks = sum(filtered_df_B['action'] == 'click')\n",
    "control_clicks, experiment_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3332, 2996)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_no_clicks = sum(filtered_df_A['action'] == 'view')\n",
    "experiment_no_clicks = sum(filtered_df_B['action'] == 'view')\n",
    "control_no_clicks, experiment_no_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 932, 3332],\n",
       "       [ 928, 2996]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table = np.array([\n",
    "                            (control_clicks, control_no_clicks),\n",
    "                            (experiment_clicks, experiment_no_clicks)\n",
    "])\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.636160051233291,\n",
       " 0.056537191086915774,\n",
       " 1,\n",
       " array([[ 968.61748901, 3295.38251099],\n",
       "        [ 891.38251099, 3032.61748901]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the p-value is above our alpha of 0.05, so we cannot reject the null hypothesis. In other words, we found no significant difference between the control and experiment groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WELP, after all that, it turns out I ran the wrong kind of test. ⊙﹏⊙∥ \n",
    "\n",
    "I suppose I'm really just comparing the conversion rates of clicks between two groups. In other words, I'm comparing two sets of numerical values, so a two-sided Welch's t-test will do it. At least, I think that's the reasoning. I'm still confused because we just worked with similar data (conversion rates) in the previous A/B testing lecture with Greg and we used a chi-squared test there, so...╰（‵□′）╯\n",
    "In any case, they make a 'count' column where each row gets the same value: 1. This can be used to calculate sums easily. I'll make it here in my filtered_df and then go from there setting up & running a two-sidded Welch's t-test. However, I don't need to that. I already put the subsets together that I need. \n",
    "What I should've done is calculated the perentages of views turn into clicks; that would give me a mean. Specifically, the \"average click rate,\" which means I'm just comparing two means, which means I use Welch's ttest. I think Welch's is also used with control/experiment stuff more, but not 100% sure on that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2797118847539016, 0.3097463284379172)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_click_rate = control_clicks/control_no_clicks\n",
    "experiment_click_rate = experiment_clicks/experiment_no_clicks\n",
    "control_click_rate, experiment_click_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-2a72acde68c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_value_welch_ttest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_click_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_click_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Flatiron School\\Phase 2\\Phase 2 Labs on GitHub\\dsc-website-ab-testing-lab\\dsc-website-ab-testing-lab\\flatiron_stats.py\u001b[0m in \u001b[0;36mp_value_welch_ttest\u001b[1;34m(a, b, two_sided)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mSet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtwo\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msided\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwish\u001b[0m \u001b[0mto\u001b[0m \u001b[0mperform\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtwo\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msided\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtest\u001b[0m \u001b[0minstead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \"\"\"\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwelch_t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwelch_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Flatiron School\\Phase 2\\Phase 2 Labs on GitHub\\dsc-website-ab-testing-lab\\dsc-website-ab-testing-lab\\flatiron_stats.py\u001b[0m in \u001b[0;36mwelch_t\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;34m\"\"\" Calculate Welch's t statistic for two samples. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mnumerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# “ddof = Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "fs.p_value_welch_ttest(control_click_rate, experiment_click_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_t(a, b):\n",
    "    \n",
    "    \"\"\" Calculate Welch's t statistic for two samples. \"\"\"\n",
    "\n",
    "    numerator = a.mean() - b.mean()\n",
    "    \n",
    "    # â€œddof = Delta Degrees of Freedomâ€�: the divisor used in the calculation is N - ddof, \n",
    "    #  where N represents the number of elements. By default ddof is zero.\n",
    "    \n",
    "    denominator = np.sqrt(a.var(ddof=1)/a.size + b.var(ddof=1)/b.size)\n",
    "    \n",
    "    return np.abs(numerator/denominator)\n",
    "\n",
    "def welch_df(a, b):\n",
    "    \n",
    "    \"\"\" Calculate the effective degrees of freedom for two samples. This function returns the degrees of freedom \"\"\"\n",
    "    \n",
    "    s1 = a.var(ddof=1) \n",
    "    s2 = b.var(ddof=1)\n",
    "    n1 = a.size\n",
    "    n2 = b.size\n",
    "    \n",
    "    numerator = (s1/n1 + s2/n2)**2\n",
    "    denominator = (s1/ n1)**2/(n1 - 1) + (s2/ n2)**2/(n2 - 1)\n",
    "    \n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "def p_value_welch_ttest(a, b, two_sided=False):\n",
    "    \"\"\"Calculates the p-value for Welch's t-test given two samples.\n",
    "    By default, the returned p-value is for a one-sided t-test. \n",
    "    Set the two-sided parameter to True if you wish to perform a two-sided t-test instead.\n",
    "    \"\"\"\n",
    "    t = welch_t(a, b)\n",
    "    df = welch_df(a, b)\n",
    "    \n",
    "    p = 1-stats.t.cdf(np.abs(t), df)\n",
    "    \n",
    "    if two_sided:\n",
    "        return 2*p\n",
    "    else:\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f204064ca1b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp_value_welch_ttest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_click_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_click_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-f5916c730e5b>\u001b[0m in \u001b[0;36mp_value_welch_ttest\u001b[1;34m(a, b, two_sided)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mSet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtwo\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msided\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwish\u001b[0m \u001b[0mto\u001b[0m \u001b[0mperform\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtwo\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msided\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtest\u001b[0m \u001b[0minstead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwelch_t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwelch_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-f5916c730e5b>\u001b[0m in \u001b[0;36mwelch_t\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"\"\" Calculate Welch's t statistic for two samples. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnumerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# â€œddof = Delta Degrees of Freedomâ€�: the divisor used in the calculation is N - ddof,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "p_value_welch_ttest(control_click_rate, experiment_click_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b9936e58265e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_value_welch_ttest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_clicks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_clicks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Flatiron School\\Phase 2\\Phase 2 Labs on GitHub\\dsc-website-ab-testing-lab\\dsc-website-ab-testing-lab\\flatiron_stats.py\u001b[0m in \u001b[0;36mp_value_welch_ttest\u001b[1;34m(a, b, two_sided)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mSet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtwo\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msided\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwish\u001b[0m \u001b[0mto\u001b[0m \u001b[0mperform\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtwo\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msided\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtest\u001b[0m \u001b[0minstead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \"\"\"\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwelch_t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwelch_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Flatiron School\\Phase 2\\Phase 2 Labs on GitHub\\dsc-website-ab-testing-lab\\dsc-website-ab-testing-lab\\flatiron_stats.py\u001b[0m in \u001b[0;36mwelch_t\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;34m\"\"\" Calculate Welch's t statistic for two samples. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mnumerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# “ddof = Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "fs.p_value_welch_ttest(control_clicks, experiment_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this won't work because I already calculated a mean - the \"average click rate\" - and the flatiron_stats function needs an array (or at least some sort of group) of numbers. I do remember that the solution approached the Welch's TTest here differently with a 'count' column they could sum up. \n",
    "\n",
    "I tried to do it my way, but I wind up with a preexisting mean the function isn't designed for. Wait, what if I just take the \"sum\" part out of my control_clicks/no_clicks & experiment_click/no_clicks and then run it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_clicks = filtered_df_A['action'] == 'click'\n",
    "experiment_clicks = filtered_df_B['action'] == 'click'\n",
    "control_no_clicks = filtered_df_A['action'] == 'view'\n",
    "experiment_no_clicks = filtered_df_B['action'] == 'view'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026743886922199422"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.p_value_welch_ttest(control_clicks, experiment_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that finally won't throw an error, but why is my result different than the solution? It must be in how the solution sets up the test. At this point, I've spent hours trying to figure it out on my own, so let's investigate why the solution is producing a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>action</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-24 17:42:27.839496</td>\n",
       "      <td>804196</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-24 19:19:03.542569</td>\n",
       "      <td>434745</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-24 19:36:00.944135</td>\n",
       "      <td>507599</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-24 19:59:02.646620</td>\n",
       "      <td>671993</td>\n",
       "      <td>control</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-24 20:26:14.466886</td>\n",
       "      <td>536734</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp      id       group action  count\n",
       "0  2016-09-24 17:42:27.839496  804196  experiment   view      1\n",
       "1  2016-09-24 19:19:03.542569  434745  experiment   view      1\n",
       "2  2016-09-24 19:36:00.944135  507599  experiment   view      1\n",
       "3  2016-09-24 19:59:02.646620  671993     control   view      1\n",
       "4  2016-09-24 20:26:14.466886  536734  experiment   view      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count'] = 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes:\tControl: 3332\tExperiment: 2996\n",
      "Total Clicks:\tControl: 932.0\tExperiment: 928.0\n",
      "Average click rate:\tControl: 0.2797118847539016\tExperiment: 0.3097463284379172\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>action</th>\n",
       "      <th>click</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183089</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183248</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183524</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "action  click  view\n",
       "id                 \n",
       "182994    1.0   1.0\n",
       "183089    0.0   1.0\n",
       "183248    1.0   1.0\n",
       "183515    0.0   1.0\n",
       "183524    0.0   1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control = df[df.group=='control'].pivot(index='id', columns='action', values='count')\n",
    "control = control.fillna(value=0)\n",
    "\n",
    "experiment = df[df.group=='experiment'].pivot(index='id', columns='action', values='count')\n",
    "experiment = experiment.fillna(value=0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sample sizes:\\tControl: {}\\tExperiment: {}\".format(len(control), len(experiment)))\n",
    "print(\"Total Clicks:\\tControl: {}\\tExperiment: {}\".format(control.click.sum(), experiment.click.sum()))\n",
    "print(\"Average click rate:\\tControl: {}\\tExperiment: {}\".format(control.click.mean(), experiment.click.mean()))\n",
    "control.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004466402814337078"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.p_value_welch_ttest(control.click, experiment.click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, so the binary count column is set up such that all views get a 1, but clicks only get a count if it says \"click.\" Subsequently, it will produce a sample you can average within the welch ttest function. I guess I'm still confused why the output is different because my version of a pivot table (as filtered_df) also produces such an input. Let's explore their pivot table some more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "182994    1.0\n",
       "183089    0.0\n",
       "183248    1.0\n",
       "183515    0.0\n",
       "183524    0.0\n",
       "         ... \n",
       "936786    0.0\n",
       "937003    0.0\n",
       "937073    0.0\n",
       "937108    0.0\n",
       "937217    1.0\n",
       "Name: click, Length: 3332, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control.click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       False\n",
       "9       False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "        ...  \n",
       "8178    False\n",
       "8181    False\n",
       "8182     True\n",
       "8186    False\n",
       "8187    False\n",
       "Name: action, Length: 4264, dtype: bool"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here's my attempt at the same thing from earlier:\n",
    "control_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I have a boolean thing going as opposed to a numerical column and it's longer, so...in the interest of time, let's keep in mind that when we're compiling subsets and numerical inputs for stats tests, it may be better to convert our values ('view'/'click', etc.) into numerical values with something like this 'count' column and we should get better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Results\n",
    "\n",
    "One sensible formulation of the data to answer the hypothesis test above would be to create a binary variable representing each individual in the experiment and control group. This binary variable would represent whether or not that individual clicked on the homepage; 1 for they did and 0 if they did not. \n",
    "\n",
    "The variance for the number of successes in a sample of a binomial variable with n observations is given by:\n",
    "\n",
    "## $n\\bullet p (1-p)$\n",
    "\n",
    "Given this, perform 3 steps to verify the results of your statistical test:\n",
    "1. Calculate the expected number of clicks for the experiment group, if it had the same click-through rate as that of the control group. \n",
    "2. Calculate the number of standard deviations that the actual number of clicks was from this estimate. \n",
    "3. Finally, calculate a p-value using the normal distribution based on this z-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Calculate the expected number of clicks for the experiment group, if it had the same click-through rate as that of the control group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected number of clicks for the experiment group 712.3933968032143\n",
      "click-through rate of control group: 0.2797118847539016\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "p_experiment_clicks = sum(experiment.click)/len(experiment.click)\n",
    "expected_clicks_experiment = len(control.click) * (p_experiment_clicks*(1-p_experiment_clicks))\n",
    "print(\"expected number of clicks for the experiment group\", expected_clicks_experiment)\n",
    "print(\"click-through rate of control group:\", (control.click.sum()/len(control.click)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure if I'm answering the question above correctly; it feels like I'm doing what it asks, \n",
    "but I don't think I get what it's asking. WHat does the solution do here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838.0168067226891"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_rate = control.click.mean()\n",
    "expected_experiment_clicks_under_null = control_rate * len(experiment)\n",
    "expected_experiment_clicks_under_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, it's asking what the rate of clicks is for the control group and then we take that and apply it to the length of the experiment group to set up expectations for what that rate would be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Calculate the number of standard deviations that the actual number of clicks was from this estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.568547907005815"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "#ok, wow, this going back to basics on s.d. and variance and I really had no idea what to do,\n",
    "# so first you have to calculate the variance, like they showed above. Then, you have to \n",
    "# remember that the s.d. is the square root of the variance. \n",
    "n = len(experiment.click)\n",
    "#The p for our purposes will be control_rate because that's what we used above\n",
    "p = control_rate\n",
    "variance = n*(p*(1-p))\n",
    "std = np.sqrt(variance)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.6625360854823588"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we (should so obviously and easily) recall that we measure the number of \n",
    "# s.d.'s from a mean with a z-score. z-scores are (x-mu)/s.d.:\n",
    "\n",
    "#z_score = (expected_experiment_clicks_under_null - control.click.mean())/std\n",
    "#（＞人＜；）\n",
    "z_score = (expected_experiment_clicks_under_null - sum(experiment.click))/std\n",
    "z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, the solution's numerator order is reversed, but I feel like according to the z-score\n",
    "formula, I set it up the right way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(experiment.click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, it's less so it should be -3.66, but I guess either way works if the question is simply\n",
    "\"how many s.d.'s away\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: \n",
    "Finally, calculate a p-value using the normal distribution based on this z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012486528006951198"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "#If I'm reading my notes right, all I have to do is this:\n",
    "stats.norm.cdf(z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "Does this result roughly match that of the previous statistical test?\n",
    "\n",
    "> Comment: No, those are different p-values and something is wrong and oh wait, never mind, I see now that\n",
    "even though this p-value is lower, they would both lead to rejecting the null, which is true, so yes it\n",
    "can be said to 'roughly match' the previous stats test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you continued to get more practice designing and conducting AB tests. This required additional work preprocessing and formulating the initial problem in a suitable manner. Additionally, you also saw how to verify results, strengthening your knowledge of binomial variables, and reviewing initial statistical concepts of the central limit theorem, standard deviation, z-scores, and their accompanying p-values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
